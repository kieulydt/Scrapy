{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nội dung chính "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Giới thiệu\n",
    "2. Cài đặt\n",
    "3. Khái niệm chính <br/>\n",
    "    3.1: Selectors <br/>\n",
    "    3.2: Request và Response <br/>\n",
    "    3.3: Command line <br/>\n",
    "    3.4: Spiders <br/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrapy là gì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy là một framework được viết bằng Python, nó cấp sẵn 1 cấu trúc tương đối hoàn chỉnh để thực hiện việc crawl và extract data từ website một cách nhanh chóng và dễ dàng. Ví dụ như lấy toàn bộ hình ảnh trên 1 website; các bài viết trên các trang báo; thông tin dữ liệu các sản phẩm moblie, ô tô; các thông tin public trên facebook;..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Người dùng chỉ cần bổ sung thêm định nghĩa về dữ liệu cần lấy là xong, ví dụ như URL bắt đầu là gì, link chuyển qua trang mới, các thông tin cần lấy ở mỗi trang là gì..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cài đặt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy chạy trên Python 2.7 và Python 3.5 trở lên trong CPython và PyPy 5.9 trở lên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu như bạn sử dụng Anaconda hoặc Miniconda, bạn có thể cài đặt gói từ conda-forge channel. Để cài đặt Scrapy sử dụng `conda`, chạy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conda install -c conda-forge scrapy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài ra, nếu bạn đã quen với việc cài đặt các gói Python, bạn có thể cài đặt Scrapy từ PyPI với:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install Scrapy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Các khái niệm cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Kiến trúc Scrapy:<b/><br/>\n",
    "<img src=\"kientruc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tạo project scrapy thì ta sử dụng lệnh: `scrapy startproject <nameproject>`.<br/>\n",
    "Đây là cấu trúc thư mục khi vừa tạo thông qua scrapy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scraper/\n",
    "├── scraper                         # nơi chứa code của dự án\n",
    "│   ├── __init__.py\n",
    "│   ├── items.py                    # nơi định nghĩa các trường dữ liệu cần lưu vào db\n",
    "│   ├── pipelines.py                # nơi xử lý các item trích xuất được và lưu vào db\n",
    "│   ├── settings.py                 # cấu hình thêm các phần mở rộng (middlewares) và các thông số cấu hình khác\n",
    "│   └── spiders                     # thư mục chứa các spider\n",
    "│       └── __init__.py\n",
    "└── scrapy.cfg                      # file cấu hình về deploy và settings của project`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi quét các trang web, tác vụ phổ biến nhất cần thực hiện là trích xuất dữ liệu từ nguồn HTML. Scrapy có cơ chế riêng để trích xuất dữ liệu. Chúng chọn một số thành phần nhất định của tài liệu HTML được chỉ định bởi các biểu thức XPath hoặc CSS. XPath để chọn các nút trong tài liệu XML, cũng có thể được sử dụng cho các tài liệu HTML. CSS là ngôn ngữ để áp dụng các kiểu cho các tài liệu HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truy vấn các phản hồi bằng XPath và CSS ta sử dụng:  `response.xpath()` và `response.css()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ:\n",
    "<br/>\n",
    "`>>> response.xpath('//span/text()').get()`\n",
    "<br/>\n",
    "'good'\n",
    "<br/>\n",
    "`>>> response.css('span::text').get()`\n",
    "<br/>\n",
    "'good'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Một số phương thức"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi trích xuất dữ liệu ta sử dụng một số phương thức để trả về dữ liệu theo ý muốn. Có thể là trả về một mảng dữ liệu hay là phần tử đầu tiên của mảng dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"method_extract.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xét ví dụ với một đoạn HTML dưới đây."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "sel = Selector(text=\"\"\"\n",
    "<html>\n",
    " <head>\n",
    "  <base href='http://example.com/' />\n",
    "  <title>Example website</title>\n",
    " </head>\n",
    " <body>\n",
    "  <div id='images'>\n",
    "   <a href='image1.html'>Name: My image 1 <br /><img src='image1_thumb.jpg' /></a>\n",
    "   <a href='image2.html'>Name: My image 2 <br /><img src='image2_thumb.jpg' /></a>\n",
    "   <a href='image3.html'>Name: My image 3 <br /><img src='image3_thumb.jpg' /></a>\n",
    "   <a href='image4.html'>Name: My image 4 <br /><img src='image4_thumb.jpg' /></a>\n",
    "   <a href='image5.html'>Name: My image 5 <br /><img src='image5_thumb.jpg' /></a>\n",
    "  </div>\n",
    " </body>\n",
    "</html>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Chú ý:</b> Khi thực hiện crawl trên web thì phần text của response chính là mã nguồn đc scrapy tải xuống  hay nói cách khác response = sel. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>title::text</b>: Trích chọn text trong thẻ title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example website'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('title::text').extract_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>*::text</b> chọn tất cả text ở trong các thẻ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n   ',\n",
       " 'Name: My image 1 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 2 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 3 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 4 ',\n",
       " '\\n   ',\n",
       " 'Name: My image 5 ',\n",
       " '\\n  ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('#images *::text').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>foo::text</b> trả về kết quả không nếu phần tử foo tồn tại nhưng không chứa text.\n",
    "<br/>\n",
    "Sử dụng <b>default=''</b> nếu bạn muốn trả về string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('img::text').getall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('img::text').get(default='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>a::attr(href)</b> chọn giá trị thuộc tính href của links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('a::attr(href)').getall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trích xuất thông tin trong thẻ div có id = images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<div id=\"images\">\\n   <a href=\"image1.html\">Name: My image 1 <br><img src=\"image1_thumb.jpg\"></a>\\n   <a href=\"image2.html\">Name: My image 2 <br><img src=\"image2_thumb.jpg\"></a>\\n   <a href=\"image3.html\">Name: My image 3 <br><img src=\"image3_thumb.jpg\"></a>\\n   <a href=\"image4.html\">Name: My image 4 <br><img src=\"image4_thumb.jpg\"></a>\\n   <a href=\"image5.html\">Name: My image 5 <br><img src=\"image5_thumb.jpg\"></a>\\n  </div>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css('div#images').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta có thể chọn lọc ra một số thành phần chính xác trên một trang web bằng cách sử dụng XPath. Có thể lấy XPath dễ dàng bằng tool hay sử dụng Chrome để tìm XPath."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ chúng ta sẽ lấy XPath trên stack overflow. Click chuột phải vào câu hỏi đầu tiên và chọn kiểm tra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"xp_0.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta lấy XPath của phần tử đầu tiên `<div class=\"summary\">`, kết quả sẽ tương tự `//*[@id=\"question-summary-59818222\"]/div[2]`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"xp_1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ test trong Javascript console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"xp_2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qua ví dụ trên ta có thể dễ dàng lấy XPath của bất kỳ phần tử nào"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Request và Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy sử dụng đối tượng Request và Response để thu thập dữ liệu websites.<br/>\n",
    "Thông thường các đối tượng Request được tạo trong spider và truyền qua hệ thống cho đến khi đến trình download, thực thi yêu cầu và trả về đối tượng Response di chuyển trở lại spider đã gửi Request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Command line tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapy được điều khiển thông qua command-line tool. Scrapy cung cấp một số lệnh, với nhiều mục đích thì sẽ sử dụng các nhóm lệnh khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một số lệnh command-line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"commandline.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ về sử dụng scrapy shell. Đầu tiên mở cmd chạy command `scrapy shell [url]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"shell.PNG\">\n",
    "<br/>\n",
    "<img src=\"shell1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó có thể trực tiếp sử dụng các Selector để trích xuất trực tiếp, thực hiện điều này giúp kiểm tra một cách trực quan hơn. Ví dụ ta muốn tách title của bài báo, nhập `response.css('title::text').get()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"shell2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4: Spiders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiders là class được viết bởi người dùng, xác định một hoặc một nhóm trang web nhất định sẽ được quét, bao gồm cách thực hiện thu thập thông tin và cách trích xuất dữ liệu có cấu trúc từ các trang web đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với Spiders, quá trình thu thập dữ liệu có chu trình như sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bạn bắt đầu bằng cách tạo các yêu cầu bạn đầu để thu thập dữ liệu từ URL đầu tiên và chỉ định chức năng gọi lại được gọi với phản hồi từ các yêu cầu đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Trong hàm gọi lại, bạn phân tích cú pháp phản hồi và trả về các ký tự với dữ liệu được trích xuất.  Những yêu cầu đó cũng có thể chứa một yêu cầu gọi lại, sau đó cũng sẽ được Scrapy duyệt và phản hồi lại yêu cầu đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cuối cùng, các mục được trả về từ spiders sẽ được duy trì trong CSDL hoặc đươc ghi vào một tệp bằng cách sử dụng Feed exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### items.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chứa các định nghĩa thông tin mình muốn extract. Giả sử tạo thư mục vnexpress, ta định nghĩa item VnexpressItem trong file items.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.item import Item, Field\n",
    "\n",
    "class VnexpressItem(Item):\n",
    "    # define the fields for your item here like:\n",
    "    title = Field()\n",
    "    url = Field()\n",
    "    content = Field()\n",
    "    author = Field()\n",
    "    description = Field()\n",
    "    publish_date = Field()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapy.Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Định nghĩa cách chuyển giữa các trang và cách lấy thông tin. ví dụ định nghĩa domain thực hiện việc scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một số phương thức và thuộc tính chính:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"method_scrapy.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ: Crawl dữ liệu trên báo vnexpress \n",
    "<br/>\n",
    "<a href=\"https://vnexpress.net/du-lich/viet-nam-huong-den-bau-troi-mo-asean-4001184.html\">link báo</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước tiên ta tạo một file myspider.py trong thư mục spiders đã được tạo. Thư mục này là nơi chúng ta đưa ra các chỉ định cho Scrapy biết chính xác chúng ta muốn thu thập dữ liệu gì. Trong thư mục này các bạn có thể định nghĩa các spiders khác nhau cho các trang web khác nhau. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu muốn trả về item thì ta phải import item mà ta đã định nghĩa trong file items.py trong project. Dữ liệu xuất ra được sắp xếp theo key của mỗi item, sắp xếp theo thứ tự abc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "#from vnexpress.items import VnexpressItem\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"vnexpress\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = ['https://vnexpress.net/du-lich/viet-nam-huong-den-bau-troi-mo-asean-4001184.html']\n",
    "        for url in urls:\n",
    "            #Phương thức call back gọi lại hàm parse_article khi gửi request đến url\n",
    "            #hàm parse_article sẽ xử lý phản hồi đã được tải khi request url \n",
    "            request = scrapy.Request(url=url, callback=self.parse_artilce) \n",
    "            request.meta['url'] = url\n",
    "            yield request\n",
    "\n",
    "    def parse_artilce(self, response):\n",
    "        title = response.xpath('//*[@id=\"col_sticky\"]/h1/text()').extract()[0].strip()\n",
    "        description = response.xpath('//*[@id=\"col_sticky\"]/p[1]').extract()[0].strip()\n",
    "        content = response.xpath('//*[@id=\"col_sticky\"]/article').extract()[0].strip()\n",
    "        author = response.xpath('//*[@id=\"col_sticky\"]/p[2]/strong/text()').extract()[0].strip()\n",
    "        publish_date = response.xpath('//*[@id=\"col_sticky\"]/header/span/text()').extract()[0].strip()\n",
    "        \n",
    "        item = VnexpressItem()\n",
    "        item['title'] = title\n",
    "        item['url'] = response.meta['url']\n",
    "        item['content'] = content\n",
    "        item['description'] = description\n",
    "        item['author'] = author\n",
    "        item['publish_date'] = publish_date\n",
    "        \n",
    "        yield item\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đó sẽ chạy lệnh ở command line để thực hiện lấy các thông tin mà spider trích xuất."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scrapy crawl vnexpress`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu muốn xuất ra file json thì sử dụng:<br/>\n",
    "<br/>\n",
    "`scrapy crawl vnexpress -o output.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây sử dụng request.meta và response.meta, trong đó response.meta trả về giá trị lưu ở request.meta trước khi request url. Hay nói cách khác đó là: truyền đối số cho các hàm có thể gọi được và nhận các đối số đó trong cuộc gọi lại thứ hai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để Insert các kết quả tìm được vào database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trích xuất tên, loại, giá, nơi sản xuất, cỡ của tất cả các loại giày ở trang web https://adidasstore.vn/ rồi lưu lại kết quả vào file adidas.json.<br/>\n",
    "Chú ý: loại là giày adidasneo hay adidas nam hay adidas nữ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tham khảo thêm tại https://github.com/kieulydt/MobileCrawler :v :v :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bài báo cáo còn nhiều sai sót và hổng do bản tính lười biếng, mong thí chủ lượng thứ :(((("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
